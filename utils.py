# utils.py

import torch
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt

def imprimir_distribucion_clases_post_augmentation(loader, n_classes=6, title="DistribuciÃ³n de clases post-augmentation"):
    """
    Calcula y muestra la distribuciÃ³n porcentual de pÃ­xeles por cada clase
    en un DataLoader despuÃ©s de que las transformaciones han sido aplicadas.

    Args:
        loader (DataLoader): El DataLoader a analizar (ej. train_loader).
        n_classes (int): El nÃºmero total de clases en la segmentaciÃ³n.
        title (str): TÃ­tulo para la impresiÃ³n de resultados.
    """
    print(f"\n--- {title} ---")
    class_counts = torch.zeros(n_classes, dtype=torch.int64)
    total_pixels = 0

    # Itera sobre el loader para acceder a las mÃ¡scaras aumentadas
    loop = tqdm(loader, desc="Analizando distribuciÃ³n")
    for _, masks in loop:
        # masks tiene shape (N, H, W)
        total_pixels += masks.numel() # N * H * W

        # Cuenta los pÃ­xeles para cada clase en el batch actual
        # torch.bincount es muy eficiente para esta tarea
        # Aplanamos todas las mÃ¡scaras del batch a un solo vector
        counts = torch.bincount(masks.flatten().long(), minlength=n_classes)
        class_counts += counts

    # Calcula el porcentaje para cada clase
    class_distribution = (class_counts.float() / total_pixels) * 100

    # ------------------------------------------------------------------
    # ### NUEVO: pesos de importancia inversamente proporcionales
    # FÃ³rmula clÃ¡sica:   w_i  =  total_pix / (n_clases * count_i)
    # â‡’  clases raras  â†’  peso grande,   clases frecuentes â†’ pequeÃ±o.
    # Normalizamos para que el promedio sea 1 (opcional pero prÃ¡ctico).
    eps = 1e-8                                         # evita divisiÃ³n por 0
    raw_weights = total_pixels / (n_classes * (class_counts.float() + eps))
    class_weights = raw_weights / raw_weights.mean()   # media = 1
    # ------------------------------------------------------------------

    # Imprime los resultados
    print(f"NÃºmero total de pÃ­xeles analizados: {total_pixels}")
    print("DistribuciÃ³n final de pÃ­xeles por clase:")
    for i, dist in enumerate(class_distribution):
        print(f"  Clase {i}: {dist:.4f}%  ({class_counts[i]} pÃ­xeles)")
    
    # ------------------------------------------------------------------
    # ### NUEVO: muestra los pesos calculados
    print("\nPesos de importancia por clase (para CrossEntropy/Focal):")
    for i, w in enumerate(class_weights):
        print(f"  Clase {i}: {w:.4f}")
    # ------------------------------------------------------------------

    print("-" * (len(title) + 6))

# =================================================================================
# FUNCIÃ“N DE RECORTE (AÃ‘ADIDA)
# =================================================================================
def crop_around_classes(
    image: np.ndarray,
    mask: np.ndarray,
    classes_to_find: list[int] = [1, 2, 3, 4, 5],
    margin: int = 10  # <--- AÃ‘ADIDO: Un pequeÃ±o margen puede ser Ãºtil
) -> tuple[np.ndarray, np.ndarray]:
    """
    Recorta un rectÃ¡ngulo alrededor de todos los pÃ­xeles que pertenecen a las
    clases especificadas en la mÃ¡scara.
    """
    # is_class_present serÃ¡ 2D (H,W) ya que la mÃ¡scara de entrada es (H,W,1)
    is_class_present = np.isin(mask.squeeze(), classes_to_find)

    ys, xs = np.where(is_class_present)

    if ys.size == 0:
        return image, mask # Devuelve la mÃ¡scara original (H,W,1)

    y_min, y_max = ys.min(), ys.max()
    x_min, x_max = xs.min(), xs.max()

    y0 = max(0, y_min - margin)
    y1 = min(mask.shape[0], y_max + margin + 1)
    x0 = max(0, x_min - margin)
    x1 = min(mask.shape[1], x_max + margin + 1)

    cropped_image = image[y0:y1, x0:x1]
    # Se recorta la mÃ¡scara (H,W,1) y mantiene sus 3 dimensiones
    cropped_mask = mask[y0:y1, x0:x1, :]

    return cropped_image, cropped_mask

def save_performance_plot(train_history, val_history, save_path):
    """
    Guarda un grÃ¡fico comparando el mIoU de entrenamiento y validaciÃ³n por Ã©poca.

    Args:
        train_history (list): Lista con los valores de mIoU de entrenamiento por Ã©poca.
        val_history (list): Lista con los valores de mIoU de validaciÃ³n por Ã©poca.
        save_path (str): Ruta donde se guardarÃ¡ el grÃ¡fico en formato PNG.
    """
    epochs = range(1, len(train_history) + 1)
    
    plt.style.use('seaborn-v0_8-darkgrid') # Estilo visual atractivo
    fig, ax = plt.subplots(figsize=(12, 7))

    # Graficar ambas curvas
    ax.plot(epochs, train_history, 'o-', color="xkcd:sky blue", label='Entrenamiento (mIoU)', markersize=4)
    ax.plot(epochs, val_history, 'o-', color="xkcd:amber", label='ValidaciÃ³n (mIoU)', markersize=4)

    # TÃ­tulos y etiquetas
    ax.set_title('Rendimiento del Modelo: mIoU por Ã‰poca', fontsize=16, weight='bold')
    ax.set_xlabel('Ã‰poca', fontsize=12)
    ax.set_ylabel('mIoU (Mean Intersection over Union)', fontsize=12)
    
    # Leyenda, cuadrÃ­cula y lÃ­mites
    ax.legend(fontsize=11, frameon=True, shadow=True)
    ax.grid(True, which='both', linestyle='--', linewidth=0.5)
    ax.set_ylim(0, max(1.0, max(val_history)*1.1)) # LÃ­mite Y hasta 1.0 o un poco mÃ¡s del mÃ¡ximo
    ax.set_xticks(epochs) # Asegura que se muestren todas las Ã©pocas si no son demasiadas

    plt.tight_layout()
    plt.savefig(save_path, dpi=150) # Guardar con buena resoluciÃ³n
    plt.close(fig) # Liberar memoria
    print(f"ðŸ“ˆ GrÃ¡fico de rendimiento guardado en '{save_path}'")

def check_metrics(loader, model, n_classes: int = 6, device: str = "cuda"):
    """
    Calcula mÃ©tricas macro-promedio (mIoU y Dice) *sin* bucle por clase,
    usando una matriz de confusiÃ³n acumulada en GPU.
    """
    eps = 1e-8
    conf_mat = torch.zeros((n_classes, n_classes), dtype=torch.float64, device=device)

    model.eval()
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device, non_blocking=True)
            y = y.to(device, non_blocking=True).long()

            logits = model(x)
            logits = logits[0] if isinstance(logits, tuple) else logits
            preds  = torch.argmax(logits, dim=1)

            # â”€â”€ Sustituimos el bucle TP/FP/FN por una matriz de confusiÃ³n en GPU â”€â”€
            flattened = (preds * n_classes + y).view(-1).float()
            conf      = torch.histc(
                flattened,
                bins = n_classes * n_classes,
                min  = 0,
                max  = n_classes * n_classes - 1
            ).view(n_classes, n_classes)

            conf_mat += conf
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    intersection = torch.diag(conf_mat)                  # TP por clase
    pred_sum     = conf_mat.sum(dim=1)                   # TP + FP
    true_sum     = conf_mat.sum(dim=0)                   # TP + FN
    union        = pred_sum + true_sum - intersection    # TP + FP + FN

    iou_per_class  = (intersection + eps) / (union + eps)
    dice_per_class = (2 * intersection + eps) / (pred_sum + true_sum + eps)

    miou_macro  = iou_per_class.mean()
    dice_macro  = dice_per_class.mean()

    print("IoU por clase :", iou_per_class.cpu().numpy())
    print("Dice por clase:", dice_per_class.cpu().numpy())
    print(f"mIoU macro = {miou_macro:.4f} | Dice macro = {dice_macro:.4f}")

    model.train()
    return miou_macro, dice_macro